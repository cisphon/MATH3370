Jesse Wright
L20407623

MATH 3370 F

I ended up doing a lot of my homework with Rcpp. It's basically an extension for R that allows me to use C++ code to do whatever I want. I basically programmed a lot of the functions like trimmed mean and standard deviation in C++ and used them in R to assist myself while doing these homework assignments. Check out the src folder on my github link below, which contains my code and the texts folder which contains the data in .txt files.

Here's my repository I used to work on my homework:
https://github.com/cisphon/RStatistics

Section 1.1 – Problems 2-8

	2:
		a. 10ft, 15ft, 20ft, 25ft
		b. 300pages, 250pages, 350pages, 400pages
		c. 4, 5, 6, 7   
		d. 1.2g, 3.2g, 2.2g, 4g

	3:
		a. 
			How likely is it that more than half the computers will need or will have needed service? What is the expected number among the 100 that need warranty service? How likely is it that the number needing warranty service will exceed the expected number by more than 10?

		b. 
			Suppose that 30 of the 100 sampled needed warranty service. How confident can we be that the proportion of all such computers needing warranty service is between 0.10 or 0.24? Does the sample provide compelling evidence for concluding that more than 10% of all such computers need warranty service?

	4:
		a. 
			Concrete populations: # students at lamar, # people filed taxes, # walmarts in the us.  
			Hypothetical populations: # of people in the world, # people with coronavirus, # people with aids.
		b.
			The concrete population: All the pages in a book
			The probability question: If you take 100 random pages from the book, what is the probability that it is the beginning of the chapter?	
			The inferential statistics question: Is there any evidence that this book would teach anything?
			
			The hypothetical population: The people who read this piece of text.
			The probability question: What is the probability that 10 people read this?
			The inferential statistics question: Is there any evidence that shows the text has been read?

	5:
		a.	No. A sample of the existing population would be a portion of the students.
		b.	Yes. Randomizing the groups helps against bias and makes them similar as possible.
		c.	There wouldn't be anything to compare it with if all the students were put in the treatment group.

	6:
		It would be an enumerative study because the CSU administrator isn't interested in changing the system that changes the resulting data.		

	7:
		It would be an enumerative study because the CSU administrator isn't interested in changing the system that changes the resulting data.	

	8:
		a.	There are 3 factors and they all have 2 possible states. So it's 2^3 = 8 observations.
		b.	This is an analytic study because they are interested in changing the system that changes the resulting data.

Section 1.3 – Problems 34-38
	34:
		a.	The sample mean for the urban is 21.54 and the farm is 8.56. The urban is roughly 3x bigger than the farm.
				Just add all the numbers in the urban together and divide it by the number of urban numbers to compute the mean (in this case, there are 11 numbers). 
				It's the same way method to computer the farm mean.
		
		b.	The sample median for the urban is 17 and the farm is 8.9. The urban is approximately 2x bigger than the farm.
				The median isn't affected by the large number that the urban has (which is 80.0).
		
		c.	The trimmed mean for the urban data is 17 and the farm is 8.24. The way to compute this trimmed means is to sort the data in ascending order and then remove the first and last numbers (which are the smallest and largest numbers). After removing the numbers, then compute the mean to get the trimmed mean. This applies for both urban and farm data.
				
				The corresponding trimmed percentage for the urban is 9.09 and the farm is 6.67. The way to compute these trimmed percentages is to take (1 / n) * 100 where n is the number of urban numbers. The same method applies for the farm data.
				
				The trimmed mean is smaller than the sample mean and the trimmed median is smaller than the sample median. This applies for both urban and farm.
								

	35:
		a.	The sample mean is 1.237 and the sample median is 0.56. They are different because they use different methods for computing the results. To compute the sample mean is to add all the numbers together and divide by the number of numbers there are. To compute the sample median is to sort the numbers in the list by ascending order and to find the middle value. If there are an even number of numbers then just add the middle values together and divide them by two.

		b.	The trimmed mean is 1.16. It is between the mean and the median (0.56(mean) < 1.16 < 1.237(median)). I found an error in the book and it says 1.118 but that is incorrect. I believe they trimmed the data twice instead of just one time. 
				
				To calculate the trimmed mean, you are supposed to first sort the array of numbers and then compute the number of numbers to remove using the following function: num = floor((n * 10) / 100), where n is the number of numbers in the array. you then remove the front and back numbers num amount of times and then compute the mean of the trimmed array. 

		c.	The 0.20 value can be incremented by 0.36 before the sample median changes. A way to do this is to increment the 0.20 value by 0.01, compute for the median and if it doesn't change, continue to decrement. once it does change, decrement 0.01 from it.

	36:
		a.
				32 | 55
				33 | 49
				34 |
				35 | 6699
				36 | 34469
				37 | 03345
				38 | 9
				39 | 2347
				40 | 23
				41 | 
				42 | 4

			It suggests that the sample mean should be where there is the most digits on the right side of the stem plot. The sample median should be a little similar.

		b.
			Sample mean: 370.692
			Sample median: 369.5

		c.
			It can approach positive infinity because it doesn't affect the sample median. It can also approach negative infinity because it doesn't affect the sample median.  

		d.
			The sample mean expressed in minutes is 6.178 minutes. Just divide every value in the array by 60 to convert the seconds into minutes, then find the mean of the minutes.
			
			The sample median expressed in minutes is 6.158 minutes. Do the same method before but then find the median of the minutes. 

	37:
			I would report the typical value as the mean. The mean is: 11.41

	38:
		a.
			The reported values are: 120 125 140 130 115 120 110 130 135
			Sort them in ascending order: 110 115 120 120 125 130 130 135 140
			Compute the median: 125

		b.
			If the value was 127.6 rather than 127.4, it would be rounded up to 130 instead of 125.
			With the new value in place, it will make the median go to 130 instead of 125.
			The median is sensitive to small changes that change the reported values (if it's a middle value).

Section  1.4 – Problems 44-48

  44: 
    a.  The sample range is 2.3. Sort the numbers in ascending order and then take the first number and subtract it from the last number. (largest number - smallest number).
    b.  The sample variance is 0.52447. First you subract 180 from each observation and then compute the sample variance by summing each number minus the mean, quantity squared divided by (n - 1), where n is the number of numbers in the array.
    c.  The sample standard deviation is 0.724203. You compute for the sample variance and then sqrt the sample variance which gives you the sample standard deviation. 
    
    d.  The sample variance is 0.52447. You do the same thing as question b except don't subract 180 from each value.
	
	45:
	  a.  The sample mean is 115.58. Just add all the numbers together and divide by the number of numbers to compute the mean. The deviations from the mean are: 0.82, 0.32, -0.98, -0.38, 0.22. The way to compute those deviations is to subract the mean from each of the numbers in the array.
	  b.  The sample variance is 0.482 and the sample standard deviation is 0.694262. 
	  c.  The sample variance is 0.482
	  d.  The sample variance of the transformed values is 0.482. They are the same.
	  
	46:
    a.  Cooler Mean (1.706) < Control Mean (1.75273) < Warmer Mean (1.07643)
        Cooler Median (1.76) < Control Median (1.9) < Warmer Median (2.305)
        There are no modes for Colloer, Control, or Warmer.
    
    b.  Cooler std. dev (0.400835) < Control std. dev (0.531321) < Warmer Median std. dev (0.777873).
    
    c.
    
    d.
    
  47:
    a.  Sample mean (14.88) < Sample Median (14.7). There is no mode.
    
    b.  Sample variance = 0.837333. To compute the sample variance, simply iterate through the numbers, subracting the median from it and squaring the quantity. Then you divide it my n-1, where n is the size of the array.
    
    c.  Sample variance = 0.837333. Before computing the sample variance, subract 13 from every number in the array and then use the sample variance algorithm to compute for it.

  48:
    a.  Urban std. dev (22.2996) is more than 3x bigger than Farm std. dev (6.08767).
    b.  
    c.

Section 2.1 – Problems 2-10
  2.
    a.  Set A = {RRR, LLL, SSS}. They do not change.
    
    b.  Set B = {RLS, RSL, LRS, LSR, SLR, SRL}. There are no duplicate per outcome
    
    c.  Set C = {RRL, RRS, RLR, RSR, LRR, SRR}. 
    d.  Set D = {RRL, RRS, RLR, RSR, LRR, SRR, LLR, LLS, LRL,
                 LSL, RLL, SLL, SSL, SSR, SLS, SRS, LSS, RSS}
    e.  Set D'= {RRR, LLL, SSS, RLS, RSL, LRS, LSR, SRL, SLR}
        C union D = {RRL, RRS, RLR, RSR, LRR, SRR, LLR, LLS, LRL,
                     LSL, RLL, SLL, SSR, SRS, SLS, RSS, LSS}
        C intersect D = C = {RRL, RRS, RLR, RSR, LRR, SRR}
  
  3.
    a.  For A, write down all the combinations where one function is nonfunctioning and two components are functioning.
        A = {FSS, SFS, SSF}. It's simply a matter of moving one F across SS.
        
    b.  A + {SSS} = {FSS, SFS, SSF, SSS}
    c.  The outcomes where the system functions are: C = {SSF, SFS, SSS}.
        As long as function values can get to the other side. It reminds me of an OR boolean gate.
        
    d.  This problem can be approached as binary. Just count from [0, 7] using true and false and then remove the values of C. 
        C' = All permutations - C 
        = {FFF, FFS, FSF, FSS, SFF, SFS, SSF, SSS} - {SSF, SFS, SSS}.
        = {FFF, FFT, FSF, FSS, SFF}.
  
  4.
    a.  This problem can also be approached like binary. Count from [0,15] using F as false and V as true.
        {FFFF,FFFV,FFVF,FFVV,FVFF,FVFV,FVVF,FVVV,
         VFFF,VFFV,VFVF,VFVV,VVFF,VVFV,VVVF,VVVV}
    
    b.  Just use the 16 outcomes to count which ones have 3 Fs
        {FFFV,FFVF,FVFF,VFFF}
    
    c.  If all four mortgages are the same they all have the same F or V value.
        {FFFF,VVVV}
    
    d.  {FFFF,FFFV,FFVF,FVFF,VFFF}, just iterate V over FFF and append FFFF.
    
    e.  C union D = {FFFF, FFFV, FFVF, FVFF, VFFF, VVVV}
        C interect D = {FFFF,VVVV} intersect {FFFF, FFFV, FFVF, FVFF, VFFF}
        = {FFFF} (the only value in common).
    
    f.  B union C = {FFFV,FFVF,FVFF,VFFF} union {FFFF,VVVV}
        = {FFFV, FFVF, FVFF, VFFF, FFFF, VVVV}
        
        B intersect C = {FFFV,FFVF,FVFF,VFFF} intersect {FFFF,VVVV}
        = {null} (there are no values in common).
  5.
    a.  You can use 3 nested for loops to express the sample space:
        for (int i = 1; i <= 3; ++i)
          for (int j = 1; j <= 3; ++j)
            for (int k = 1; k <= 3; ++k)
                cout << i << ' ' << j << ' ' << k << endl;
                
        {(1,1,1),(1,1,2),(1,1,3),(1,2,1),(1,2,2),(1,2,3),(1,3,1),
         (1,3,2),(1,3,3),(2,1,1),(2,1,2),(2,1,3),(2,2,1),(2,2,2),
         (2,2,3),(2,3,1),(2,3,2),(2,3,3),(3,1,1),(3,1,2),(3,1,3),
         (3,2,1),(3,2,2),(3,2,3),(3,3,1),(3,3,2),(3,3,3).
         
    b.  If they go to the same station, then they are the same values:
        {(1,1,1), (2,2,2), (3,3,3)}
    
    c.  The possible outcomes that they go to different stations can be
        expressed in the c++ code below:
        
        int p[] = {1, 2, 3};
  
        do {
          cout << p[0] << ' ' << p[1] << ' ' << p[2] << endl;
        } while (next_permutation(p, p+3));
        
        Which prints out...
        {(1,2,3),(1,3,2),(2,1,3),(2,3,1),(3,1,2),(3,2,1)}
        
    d.  If none of them go to 2, then look through the combinations that do not have a 2.
    
        {(1,1,1),(1,1,3),(1,3,1),(1,3,3),(3,1,1),(3,1,3),(3,3,1),(3,3,3)}
  6.
    a.  Sample Space: 
        {(3),(4),(5), 
         (1,3), (1,4), (1,5), (2,3), (2,4), (2,5),
         (1,2,3), (1,2,4), (1,2,5), (2,1,3), (2,1,4), (2,1,5)}
         
    b.  If only one book is examined, then it is the resulting book.
        {(3), (4), (5)}
    
    c.  Just remove the books from the sample space that doesn't result in 5.
    
        {(5),(1,5),(2,5),(1,2,4),(2,1,5)}
        
    d.  Just remove the possibilities in the sample space that contain 1.
    
        {(3),(4),(5), 
         (2,3), (2,4), (2,5)}
    
  7.
    a.  Let n1 = total number of objects (3 + 4 = 7)
        Let n2 = candidate A (3)
        Let n3 = candidate B (4)
        
        Use the following formula to figure out the number of permutations:
        factorial(n1) / (factorial(n2) * factorial(n3))
        = n1! / (n2! * n3!)
        = 7! / (3! * 4!) = 7*6*5*4*3*2*1 / (3*2*1 * 4*3*2*1)
        = 7*6*5 / (3*2*1) = 7*5 = 35.
        
    b.  Here are the possible outcomes:
        {AAAABBB, AAABABB, AAABBAB, AAABBBA, AABBBAA, AABBAAB, AABBABA,
         AABABAB, AABABBA, AABAABB, ABAAABB, ABAABAB, ABAABBA, ABABAAB,
         ABABABA, ABABBAA, ABBAAAB, ABBAABA, ABBABAA, ABBBAAA, BBBAAAA,
         BBABAAA, BBAABAA, BBAAABA, BBAAAAB, BAAAABB, BAAABAB, BAAABBA,
         BAABABA, BAABAAB, BAABBAA, BABAAAB, BABAABA, BABABAA, BABBAA}
         
         Simply pick the ones where A is ahead of B.
         
         {AAAABBB, AAABBAB, AAABABB, AABAABB, AABABAB}
  8.
    a.  
    b.
    c.
    d.
    e.
  9.
    a.
    b.
  10.
    a.
    b.
    
Section 2.2 – Problems 12-22

  12.
    a.  It is not possible because P(A intersect B) <= P(A) and P(A union B) <= P(B).
      
    b.  P(A union B) = P(A) + P(B) - P(A intersect B) = 0.6 + 0.4 - 0.3 = 0.7
    c.  P(A union B)' = 1 - P(A union B) = 1 - 0.7 = 0.3
    d.  P(A intersect B') = P(A) - P(A intersect B) = 0.6 - 0.3 = 0.3
    e.  P(A) + P(B) - 2P(A intersect B) = 0.6 + 0.4 - 2 * 0.3 = 0.4
  
  13.
    a.  A1 union A2 = P(A1) + P(A2) - P(A1 intersect A2) 
        = 0.22 + 0.25 - 0.11
    
    b.  P(A1' intersect A2') = P(A1 union A2)' 
        = 1 - P(A1 union A2) = 1 - 0.36 = 0.64
        
    c.  P(A union B union C) 
        = P(A) + P(B) + P(C) - P(A intersect B) - P(C intersect B) - P(A intersect C) - P(A intersect B intersect C)
        = 0.22 + 0.25 + 0.28 - 0.11 - 0.05 - 0.07 + 0.01 = 0.51
    
    d.  A1' intersect A2' intersect A3' = (A1 union A2 union A3)'
        = 1 - P(A1 union A2 union A3)
        = 1 - 0.51 = 0.49
        
    e.  P(A1' intersect A2' intersect A3')
        = P(A3) - (P(A1 intersect A3) + P(A2 intersect A3) - P(A1' intersect A2' intersect A3))
        = 0.28 - (0.05 + 0.07 - 0.01)
        = 0.17
        
    f.  P((A1' intersect A2') union A3) = P(A1' intersect A2') + P(A3) - P(A1' intersect A2' intersect A3)
        = P(A1' intersect A2') + P(A3) - P(A3)
        = P(A1' intersect A2')
        = 1 - P(A1 union A2)
        = 1 - 0.36 = 0.64
  14.
    a.  P(A intersect B) = P(A) + P(B) - P(A union B)
        = 0.55 + 0.45 - 0.70
        = 1.00 - 0.70 = 0.30
    b.  P(A union B)' = 1 - P(A intersect B)
        = 1 - 0.70 = 0.30
  15.
    a.  Simply take the complement of the given P(A)
        1 - P(A) = 1 - 0.428 = 0.572
    
    b.  P(A) = 1 - P(B)
        = 1 - (P(C) + P(D))
        = 1 - (0.116 + 0.005)
        = 1 - 0.121
        = 0.879
  16.
    a.  There is no given information to work from.
    
    b.  Here are the permutations of CDP = {CDP, CPD, DCP, DPC, PCD, PDC}
        The probability that C is ranked first is 2/6 because of CDP and CPD.
    
    c.  The probabilty that C is ranked first and D is last is 1/6 because there is only one case where it happens: CPD.
  
  17.
    a.  Because P(A) = 0.30 and P(B) = 0.50. My smart-ass answer aside, there are typically more than one software packages that someone can download.
    b.  P(A)' = 1 - P(A) = 1 - 0.30 = 0.70
    c.  P(A union B) = P(A) + P(B) = 0.3 + 0.5 = 0.8
    d.  Use de morgan's law for boolean negation:
        A' intersect B' = (A union B)'
        
        P(A' intersect B') = P(A union B)'
        = 1 - P(A union B)
        = 1 - (0.8)
        = 0.2
  18. Given 15 bills and 5 of them are $10 bills, the ratio is 5/15.
      The probability that 2 bills must be first a $10 bill is:
      1 - (5/15) = 1 - 1/3 = 2/3.
  19.
    a.  P(selected joint was defective) = (10000 - 1159) / 10000 = 0.8841
    b.  P(number of joints judged defective by both) = 724 + 751 - 1159 = 316
        The probability = # of joints judged defective by only A / # joints.
        = (751 - 316) / 10000 = 0.0435
  20.
    a.  Let A1,A1,A3 denote the day, swing, and night value.
        Let B1,B2 denote unsafe conditions and unrelated to conditions.
        
        Simple events: {(A1,B1),(A1, B2),(A2,B1),(A2,B2),(A3,B1),(A3,B2)}
    
    b.  P(B1) = P(A1,B1) + (A2, B1) + P(A3,B1)
        = 0.1 + 0.08 + 0.05
        = 0.23
        The probability of an accident from unsafe conditions is 0.23.
    c.
        P(A1') = P(A2, B1) + P(A2, B2) + P(A3, B1) + P(A3, B2)
        = 0.08 + 0.2 + 0.05 + 0.22
        = 0.55
        The probability of an accident did not occur on the day shift is 0.55.
  21.
    a.  0.10.
    
    b.  A low auto deductible = .04 + .06 + .05 + .03 = .18
        A low homeowner's deductible = .06 + .10 + .03 = .19
    
    c.  In the same category (diagonal): .06 + .20 + .15 = .41
    
    d.  Just do the complement of question c: 1 - 0.41 = 0.59 
    
    e.  Sum all of the numbers on the left side: 
        P(low auto) = .18, p(low homeowner's) = 0.19 - P(L,L)
        = 0.18 + 0.19 - 0.06
        = 0.31
    
    f.  Just do the complement of question e: 1 - 0.31 = 0.69
  22.
    a.  P(stopping at both signals) = P(A,B)
        P(A union B) = P(A) + P(B) - P(A, B)
        P(A, B) = P(A) + P(B) - P(A union B)
        = 0.4 + 0.5 - 0.7 
        = 0.2
    
    b.  P(A, B') = P(A) - P(A,B) = 0.4 - 0.2 = 0.2  
        
    c.  P(A, B') + P(A', B) = 0.2 + P(B) - P(A,B) = 0.2 + 0.5 - 0.2 = 0.5  
    